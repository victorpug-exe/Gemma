{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5fd3fc",
   "metadata": {},
   "source": [
    "# ConfiguraÃ§Ã£o\n",
    "\n",
    "Antes de comeÃ§ar este tutorial, conclua as seguintes etapas:\n",
    "\n",
    "* Obtenha acesso ao Gemma fazendo login no [Hugging Face](https://huggingface.co/google/embeddinggemma-300M) e selecionando **Confirmar licenÃ§a** para um modelo Gemma.\n",
    "\n",
    "* Gere um [Token de Acesso](https://huggingface.co/docs/hub/en/security-tokens#how-to-manage-user-access-token) do Hugging Face e use-o para fazer login no Colab.\n",
    "\n",
    "Este notebook serÃ¡ executado na CPU ou na GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ed606",
   "metadata": {},
   "source": [
    "### Instalar depedencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402799a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers git+https://github.com/huggingface/transformers@v4.56.0-Embedding-Gemma-preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3416de5d",
   "metadata": {},
   "source": [
    "# Embedding Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#Use as bibliotecas `sentence-transformers` para criar uma instÃ¢ncia de uma classe de modelo com o EmbeddingGemma.\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_id = \"google/embeddinggemma-300M\"\n",
    "model = SentenceTransformer(model_id).to(device=device)\n",
    "\n",
    "print(f\"Device: {model.device}\")\n",
    "print(model)\n",
    "print(\"Total number of parameters in the model:\", sum([p.numel() for _, p in model.named_parameters()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3f3238",
   "metadata": {},
   "source": [
    "## Gerando embedding\n",
    "\n",
    "Um embedding Ã© uma representaÃ§Ã£o numÃ©rica de um texto, como uma palavra ou frase, que captura seu significado semÃ¢ntico. Essencialmente, Ã© uma lista de nÃºmeros (um vetor) que permite aos computadores compreender as relaÃ§Ãµes e o contexto das palavras.\n",
    "\n",
    "Vamos ver como EmbeddingGemma processaria trÃªs palavras diferentes `[\"Apple\", \"MaÃ§a\", \"Smartphone\"]`.\n",
    "\n",
    "EmbeddingGemma foi treinada em grandes quantidades de texto e aprendeu as relaÃ§Ãµes entre palavras e conceitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47367f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"Apple\", \"MaÃ§a\", \"Smartphone\"]\n",
    "embeddings = model.encode(words)\n",
    "print(embeddings)\n",
    "for idx, embedding in enumerate(embeddings):\n",
    "  print(f\"Embedding {idx+1} (shape): {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedfe14d",
   "metadata": {},
   "source": [
    "O modelo gera um vetor numÃ©rico para cada frase. Os vetores reais sÃ£o muito longos (768), mas para simplificar, sÃ£o apresentados com algumas dimensÃµes.\n",
    "\n",
    "A chave nÃ£o sÃ£o os nÃºmeros individuais em si, mas **a distÃ¢ncia entre os vetores**. Se representÃ¡ssemos esses vetores em um espaÃ§o multidimensional, os vetores para `maÃ§a` e `apple` estariam muito prÃ³ximos um do outro. E o vetor para `smartphone` pode estar longe de `maÃ§a`, mas perto de `apple`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab91aa",
   "metadata": {},
   "source": [
    "## Liste tarefas disponÃ­veis para fazer com esse modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ada9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tarefas disponÃ­veis:\")\n",
    "for name, prefix in model.prompts.items():\n",
    "  print(f\" {name}: \\\"{prefix}\\\"\")\n",
    "print(\"-\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a18a4eb",
   "metadata": {},
   "source": [
    "## Determinando Similaridade\n",
    "\n",
    "Nesta seÃ§Ã£o, usamos embeddings para determinar o quÃ£o sementicamente semelhantes sÃ£o as diferentes sentenÃ§as. Aqui mostramos exemplos com pontuaÃ§Ãµes de similaridade altas, mÃ©dias e baixas.\n",
    "\n",
    "Alta similaridade:\n",
    "- Frase A: â€œO chef preparou uma refeiÃ§Ã£o deliciosa para os convidadosâ€.\n",
    "- Frase B: â€œUm saboroso jantar foi preparado pelo chef para os visitantesâ€.\n",
    "- RaciocÃ­nio: Ambas as frases descrevem o mesmo evento usando palavras e estruturas gramaticais diferentes (voz ativa vs. voz passiva). Eles transmitem o mesmo significado central.\n",
    "\n",
    "SemelhanÃ§a MÃ©dia:\n",
    "- Frase A: â€œEla Ã© especialista em aprendizado de mÃ¡quinaâ€.\n",
    "- Frase B: â€œEle tem um profundo interesse em inteligÃªncia artificialâ€.\n",
    "- RaciocÃ­nio: As frases estÃ£o relacionadas porque o aprendizado de mÃ¡quina Ã© um subcampo da inteligÃªncia artificial. No entanto, eles falam sobre pessoas diferentes com diferentes nÃ­veis de envolvimento (especialista versus interesse).\n",
    "\n",
    "Baixa similaridade:\n",
    "- Frase A: \"O tempo em TÃ³quio estÃ¡ ensolarado hoje.\"\n",
    "- Frase B: â€œPreciso comprar mantimentos para a semanaâ€.\n",
    "- RaciocÃ­nio: As duas frases tratam de tÃ³picos completamente nÃ£o relacionados e nÃ£o compartilham nenhuma sobreposiÃ§Ã£o semÃ¢ntica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e8875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_high = [\n",
    "    \"O chef preparou uma refeiÃ§Ã£o deliciosa para os convidados.\",\n",
    "    \"Um jantar saboroso foi preparado pelo chef para os visitantes.\"\n",
    "]\n",
    "sentence_medium = [\n",
    "    \"Ela Ã© especialista em aprendizado de mÃ¡quina.\",\n",
    "    \"Ele tem um grande interesse em inteligÃªncia artificial.\"\n",
    "]\n",
    "sentence_low = [\n",
    "    \"O tempo em TÃ³quio estÃ¡ ensolarado hoje.\",\n",
    "    \"Preciso comprar mantimentos para a semana.\"\n",
    "]\n",
    "\n",
    "for sentence in [sentence_high, sentence_medium, sentence_low]:\n",
    "  print(\"ðŸ™‹â€â™‚ï¸\")\n",
    "  print(sentence)\n",
    "  embeddings = model.encode(sentence)\n",
    "  similarities = model.similarity(embeddings[0], embeddings[1])\n",
    "  print(\"`-> ðŸ¤– score: \", similarities.numpy()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b4f9a",
   "metadata": {},
   "source": [
    "## ClassificaÃ§Ã£o\n",
    "Nesta seÃ§Ã£o, usamos embeddings para classificar a qual Ã¡rea pertence cada sentenÃ§a de uma situaÃ§Ã£o problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fdcbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Problema de CobranÃ§a\", \"Suporte TÃ©cnico\", \"Consulta de Vendas\"]\n",
    "\n",
    "sentence = [\n",
    "\"Com licenÃ§a, o aplicativo trava na tela de login. NÃ£o funciona nem quando tento redefinir minha senha.\",\n",
    "\"Gostaria de consultar os preÃ§os e recursos do plano empresarial para uma equipe de 50 pessoas.\",\n",
    "]\n",
    "\n",
    "# Calculate embeddings by calling model.encode()\n",
    "label_embeddings = model.encode(labels, prompt_name=\"Classification\")\n",
    "embeddings = model.encode(sentence, prompt_name=\"Classification\")\n",
    "\n",
    "# Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, label_embeddings)\n",
    "print(similarities)\n",
    "\n",
    "idx = similarities.argmax(1)\n",
    "print(idx)\n",
    "\n",
    "for example in sentence:\n",
    "  print(\"ðŸ™‹â€â™‚ï¸\", example, \"-> ðŸ¤–\", labels[idx[sentence.index(example)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9117dc75",
   "metadata": {},
   "source": [
    "# Referencia\n",
    "https://ai.google.dev/gemma/docs/embeddinggemma/inference-embeddinggemma-with-sentence-transformers?hl=pt-br"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82026539",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
